{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Notebook to prep phenotype data for tensorQTL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import read_csv, read_hdf, DataFrame, read_pickle\n",
    "import nb_util_funcs as nuf\n",
    "from random import sample\n",
    "import seaborn as sns\n",
    "from seaborn import distplot , scatterplot, heatmap\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import rc_context\n",
    "import ppscore as pps\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline\n",
    "# for white background of figures (only for docs rendering)\n",
    "%config InlineBackend.print_figure_kwargs={'facecolor' : \"w\"}\n",
    "%config InlineBackend.figure_format='retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### set notebooks variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# parameters\n",
    "cohort = 'nabec'\n",
    "version = 'July_2024'\n",
    "target = 'rna_TPM' #'RNA'\n",
    "varianttype = 'SV'\n",
    "caller = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# naming\n",
    "modality = 'RNAB'\n",
    "set_name = f'{cohort}_{version}_{target}_{varianttype}_{caller}'\n",
    "cohort_version_target = f'{cohort}_{version}_{target}'\n",
    "\n",
    "\n",
    "in_dir = f'/data/CARDPB/data/NABEC/projects/QTL_paper_2024/SV-eQTL'\n",
    "geno_dir = f'{in_dir}/genotypes'\n",
    "quants_dir = f'{in_dir}/expression'\n",
    "info_dir = f'{in_dir}/sample_info'\n",
    "public_dir = f'{in_dir}/public'\n",
    "\n",
    "# in files\n",
    "quants_file = f'{quants_dir}/all_samples_salmon_genes_new.csv'\n",
    "covariates_file = f'{info_dir}/nabec.aug2020.sample_info.txt'\n",
    "\n",
    "if modality == 'METH':\n",
    "    features_file = f'{quants_dir}/EPIC_annotation_hg38.txt'    \n",
    "elif modality == 'RNAB':\n",
    "    features_file = '/data/CARDPB/resources/hg38/gencode.v43.primary_assembly.annotation.pkl'\n",
    "\n",
    "\n",
    "if varianttype == 'SNV':\n",
    "    covs_columns_to_use = ['SNVPC1', 'SNVPC2', 'SNVPC3', 'SNVPC4', 'SNVPC5','female', 'Age', 'JHU', 'MIAMI', 'SH', 'UKY', 'UMARY','EXP_PCA1', 'EXP_PCA2',\n",
    "       'EXP_PCA3', 'EXP_PCA4', 'EXP_PCA5']\n",
    "    bfile_prefix_path = f'{geno_dir}/MERGED_MAF_GENO005_plink19_ONTsamples'\n",
    "    genetic_pcs_file = f'{in_dir}/sample_info/MERGED_MAF_GENO005_plink19_ONTsamples_pca20.txt'\n",
    "elif varianttype == 'SV':\n",
    "    covs_columns_to_use = ['SVPC1', 'SVPC2', 'SVPC3', 'SVPC4', 'SVPC5','female', 'Age', 'JHU', 'MIAMI', 'SH', 'UKY', 'UMARY','EXP_PCA1', 'EXP_PCA2',\n",
    "       'EXP_PCA3', 'EXP_PCA4', 'EXP_PCA5']\n",
    "    bfile_prefix_path = f'{geno_dir}/NABEC_snifles2_2_multisample_biggerthan50bps.sorted_noBlacklist_noSuperDups_02092024_MAF_GENO_005_updateid'\n",
    "    genetic_pcs_file = f'{in_dir}/sample_info/NABEC_snifles2_2_multisample_biggerthan50bps.sorted_noBlacklist_noSuperDups_02092024_MAF_GENO_005_updateid_pca20.txt'\n",
    "elif varianttype == 'SNV_SV':\n",
    "    covs_columns_to_use = ['SVPC1', 'SVPC2', 'SVPC3', 'SNVPC4', 'SNVPC5','female', 'Age', 'JHU', 'MIAMI', 'SH', 'UKY', 'UMARY','EXP_PCA1', 'EXP_PCA2',\n",
    "       'EXP_PCA3', 'EXP_PCA4', 'EXP_PCA5']\n",
    "    bfile_prefix_path = f'{geno_dir}/SNV_sniffles_SV_merged'\n",
    "    genetic_pcs_file = f'{in_dir}/sample_info/SNV_sniffles_SV_merged_pca20.txt'    \n",
    "    \n",
    "# out files\n",
    "umap_covs_file = f'{info_dir}/{set_name}.umap.covs.csv'\n",
    "scaled_file = f'{quants_dir}/{set_name}.scaled.hdf5'\n",
    "adj_quants_file = f'{quants_dir}/{set_name}.scaled.adj.hdf5'\n",
    "tnsrqtl_pheno_file = f'{quants_dir}/{set_name}.scaled.adj.bed.gz'\n",
    "tnsrqtl_pheno_non_adj_file = f'{quants_dir}/{cohort_version_target}.scaled.bed.gz'\n",
    "\n",
    "# constants\n",
    "if modality == 'METH':\n",
    "    min_detection_rate = 0.75\n",
    "else:\n",
    "    min_detection_rate = 0.25\n",
    "\n",
    "DEBUG = False\n",
    "low_var_quartile = '75%'\n",
    "dpi_value = 50\n",
    "\n",
    "REMOVE_SAMPLE= ['UMARY-4915']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load input data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### load the quantified features matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "quants_df = read_csv(quants_file,index_col=0).set_index('ID').T\n",
    "print(quants_df.shape)\n",
    "\n",
    "if DEBUG:\n",
    "    display(quants_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#REMOVE samples\n",
    "quants_df = quants_df[~quants_df.index.isin(REMOVE_SAMPLE)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### load covariates files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covs_df = read_csv(covariates_file, index_col=0)\n",
    "# drop any duplicated indices\n",
    "print(covs_df.shape)\n",
    "covs_df = covs_df[~covs_df.index.duplicated(keep='first')]\n",
    "print(f'covariates shape {covs_df.shape}')\n",
    "if DEBUG:\n",
    "    display(covs_df.sample(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('/data/CARDPB/data/NABEC/projects/QTL_paper_2024/SV-eQTL/notebooks/ONT_samples.txt', 'r') as f:\n",
    "    ONT_samples=[i.replace('\\n','') for i in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "quants_df = quants_df[quants_df.index.isin(ONT_samples)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# check for any unexpected samples; ie probably name frmt issue\n",
    "set(quants_df.index) - set(covs_df.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### for further analysis remove the ID columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(covs_df.shape)\n",
    "#cols_to_keep = set(covs_df.columns) - set(other_id_columns) - set(exclude_addl_info_cols)\n",
    "cols_to_keep = ['Group', 'Ethnicity', 'PMI', 'Sex', 'Age', 'RIN_totalrna']\n",
    "covs_df = covs_df[cols_to_keep]\n",
    "print(f'covariates shape {covs_df.shape}')\n",
    "if DEBUG:\n",
    "    display(covs_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.012513,
     "end_time": "2024-03-01T19:01:33.159394",
     "exception": false,
     "start_time": "2024-03-01T19:01:33.146881",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### load and merge in the genetics PCs for cohort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.021071,
     "end_time": "2024-03-01T19:01:33.192820",
     "exception": false,
     "start_time": "2024-03-01T19:01:33.171749",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "genetic_components_df = pd.read_csv(genetic_pcs_file, sep='\\s+', index_col=1)\n",
    "genetic_components_df = genetic_components_df.iloc[:,1:]\n",
    "print(genetic_components_df.shape)\n",
    "covs_df = covs_df.merge(genetic_components_df, how='right', left_index=True, right_index=True)\n",
    "print(covs_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### load feature annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "if modality == 'METH':\n",
    "    features_df = read_csv(features_file, sep='\\t', header=None)\n",
    "    features_df.columns = ['Chr', 'start', 'end', 'feature']\n",
    "\n",
    "elif modality == 'RNAB':\n",
    "    features_df = read_pickle(features_file)\n",
    "    # features_df.columns = ['feature', 'chrom', 'start', 'end', 'strand']\n",
    "    # drop the ont and tag columns\n",
    "    discard_cols = features_df.columns[(features_df.columns.str.startswith('ont')) |\n",
    "                                       (features_df.columns.str.startswith('tag')) | \n",
    "                                       (features_df.columns.str.startswith('havana_')) |                                       \n",
    "                                       (features_df.columns.str.startswith('gene_alias')) | \n",
    "                                       (features_df.columns.str.startswith('transcript_alias'))]\n",
    "    features_df = features_df.drop(columns=discard_cols)\n",
    "    # subset to just 'gene' features\n",
    "    features_df = features_df.loc[features_df.feature == 'gene']\n",
    "    # now drop existing feature col so we can use that name\n",
    "    features_df = features_df.drop(columns=['feature'])\n",
    "    if modality == 'RNAB':\n",
    "        features_df = features_df.rename(columns={'seqname': 'chrom', 'gene_id': 'feature'})    \n",
    "        \n",
    "print(f'features shape {features_df.shape}')\n",
    "if DEBUG:\n",
    "    display(features_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### find IDs for features on sex chromosomes, for dropping later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sex_chr_feature_ids = features_df.loc[features_df.chrom\n",
    "                                      .isin(['chrX', 'chrY'])]['feature'].unique()\n",
    "print(len(sex_chr_feature_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check expected sex of samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vawter MP, Evans S, Choudary P et al. Gender-specific gene expression in \n",
    "#post-mortem human brain: localization to sex chromosomes. \n",
    "#Neuropsychopharmacology 2004;29:373â€“84.\n",
    "sex_genes = ['XIST','RPS4Y1','RPS4Y2','KDM5D','UTY','DDX3Y','USP9Y']\n",
    "\n",
    "if modality == 'METH':\n",
    "    sex_specific_features = features_df.loc[features_df['Chr']\n",
    "                                          .isin(['chrX', 'chrY'])]['feature'].unique()\n",
    "elif modality == 'RNAB':\n",
    "    sex_features = features_df.loc[features_df.gene_name.isin(sex_genes)]\n",
    "    sex_specific_features = sex_features.gene_name.to_list()\n",
    "\n",
    "sex_features_present = list(set(sex_specific_features) & set(quants_df.columns))\n",
    "print(f'found {len(sex_features_present)} sex features: \\n{sex_features_present}')\n",
    "quants_sex_df = quants_df[sex_features_present].copy()\n",
    "print(f'sex features matrix shape {quants_sex_df.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sex_umap_df = nuf.generate_umap_covs_df(quants_sex_df, covs_df)\n",
    "nuf.plot_umap_clusters(sex_umap_df, hue_cov='Sex', style_cov='Group')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### calculate, plot detection rates and subset well detected features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "trait_miss_rates, sample_miss_rates = nuf.calculate_detection_rates(quants_df, modality)\n",
    "nuf.plot_missing_rates(trait_miss_rates, sample_miss_rates)\n",
    "bad_call_rate_features = nuf.bad_callrate_features(trait_miss_rates, min_detection_rate)\n",
    "quants_wd_df = nuf.subset_well_detected_features(quants_df, bad_call_rate_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "trait_miss_rates, sample_miss_rates = nuf.calculate_detection_rates(quants_df, modality)\n",
    "nuf.plot_missing_rates(trait_miss_rates, sample_miss_rates)\n",
    "bad_call_rate_features = nuf.bad_callrate_features(trait_miss_rates, min_detection_rate)\n",
    "quants_wd_df = nuf.subset_well_detected_features(quants_df, bad_call_rate_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### standardize the dataset using transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "traits_scaled_df = nuf.scale_dataframe(quants_wd_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check transformation for random feature\n",
    "nuf.plot_trnsfrm_effect_example(quants_df, traits_scaled_df,\n",
    "                                bf_label=modality, \n",
    "                                af_label='quantile transformed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save scaled, well detected data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nuf.write_df_to_hdf(traits_scaled_df, scaled_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### since switching to tensorQTL can just use one large transcriptome pheno bed instead of per chrom pheno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "# get feature annots for present features\n",
    "feature_present_df = features_df.loc[features_df['gene_name'].isin(traits_scaled_df.columns)]\n",
    "\n",
    "# tensorQTL pheno bed is rows = features and columns = samples\n",
    "# where first four columns are chr, start, end, phenotype_id, then sample1 ... sampleN\n",
    "\n",
    "# create dict for renaming columns (samples) from assayid to geno_id\n",
    "#sample_col_dict = id_map.set_index('assayid').to_dict()['sampleid'] #we can skip this in this NABEC samples because it is for FOUNDIN data.\n",
    "\n",
    "# transpose the residuals df from sample x feature to feature x sample\n",
    "tresiduals_df = traits_scaled_df.transpose()\n",
    "\n",
    "# modify annots\n",
    "feature_present_df = feature_present_df[['chrom', 'start', 'end', 'gene_name', 'strand']].copy()\n",
    "feature_present_df.rename(columns={'chrom': 'chr', 'start': 'fstart', \n",
    "                                   'end': 'fend'}, inplace=True)\n",
    "# for tensorQTL 'end' column is TSS so set appropriately\n",
    "feature_present_df['end'] = np.where(feature_present_df['strand'] == '+',  \n",
    "                                     feature_present_df['fstart'], \n",
    "                                     feature_present_df['fend'])\n",
    "feature_present_df['start'] = feature_present_df['end'] - 1\n",
    "\n",
    "# there is a feature per transcript, so can be multiple entries per feature, so just keep longest\n",
    "feature_present_df['length'] = feature_present_df['fend'] - feature_present_df['fstart']\n",
    "feature_present_df.sort_values(by=['gene_name', 'length'], \n",
    "                               inplace=True, ascending=False)\n",
    "print(feature_present_df.shape)\n",
    "feature_present_df.drop_duplicates(subset=['gene_name'], keep='first', \n",
    "                                   inplace=True, ignore_index=True)\n",
    "feature_present_df.set_index('gene_name', inplace=True, drop=False)\n",
    "feature_present_df = feature_present_df.reindex(tresiduals_df.index)\n",
    "print(feature_present_df.shape)\n",
    "# insert the feature annots\n",
    "tresiduals_df.insert( 0, column='chr', value=feature_present_df['chr'])\n",
    "tresiduals_df.insert( 1, column='start', value=feature_present_df['start'])\n",
    "tresiduals_df.insert( 2, column='end', value=feature_present_df['end'])\n",
    "tresiduals_df.insert( 3, column='phenotype_id', value=feature_present_df['gene_name'])\n",
    "\n",
    "tresiduals_df\n",
    "\n",
    "# if there are any genes that were in quants but not feature annots\n",
    "# remove these with missing positions\n",
    "tresiduals_df = tresiduals_df.loc[~tresiduals_df['chr'].isna()]\n",
    "print(tresiduals_df.shape)\n",
    "# make the positions ints instead of floats\n",
    "tresiduals_df['start'] = tresiduals_df['start'].astype('int64')\n",
    "tresiduals_df['end'] = tresiduals_df['end'].astype('int64')\n",
    "\n",
    "\n",
    "\n",
    "# now rename sample ids in columns\n",
    "#tresiduals_df.rename(columns=sample_col_dict, inplace=True)\n",
    "tresiduals_df.to_csv(tnsrqtl_pheno_non_adj_file, index=False, sep='\\t', compression='gzip')"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "pytorch-gpu.1-12.m102",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-12:m102"
  },
  "kernelspec": {
   "display_name": "python/3.8",
   "language": "python",
   "name": "py3.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
